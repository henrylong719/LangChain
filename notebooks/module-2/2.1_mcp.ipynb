{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717edf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db64c0fd-9355-49e4-8290-2f2ae08eeef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import asyncio\n",
    "\n",
    "# Fix for Windows issues in Jupyter notebooks\n",
    "if sys.platform == \"win32\":\n",
    "    # 1. Use ProactorEventLoop for subprocess support\n",
    "    if not isinstance(asyncio.get_event_loop_policy(), asyncio.WindowsProactorEventLoopPolicy):\n",
    "        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())\n",
    "    \n",
    "    # 2. Redirect stderr to avoid fileno() error when launching MCP servers\n",
    "    if \"ipykernel\" in sys.modules:\n",
    "        sys.stderr = sys.__stderr__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d701224",
   "metadata": {},
   "source": [
    "## Local MCP server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f11678d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"local_server\": {\n",
    "                \"transport\": \"stdio\",\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"resources/2.1_mcp_server.py\"],\n",
    "            }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "184db1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tools\n",
    "tools = await client.get_tools()\n",
    "\n",
    "# get resources\n",
    "resources = await client.get_resources(\"local_server\")\n",
    "\n",
    "# get prompts\n",
    "prompt = await client.get_prompt(\"local_server\", \"prompt\")\n",
    "prompt = prompt[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d548fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=tools,\n",
    "    system_prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5256ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = await agent.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Tell me about the langchain-mcp-adapters library\")]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3efb5bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Tell me about the langchain-mcp-adapters library', additional_kwargs={}, response_metadata={}, id='7e4288b7-e6d9-45b0-aa53-572e5efce2b9'),\n",
      "              AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 271, 'total_tokens': 364, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D7Uvbx96KXWxR7KUKyygEuUM7t88I', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c44b9-d339-76e2-bdc2-586d4407bf4f-0', tool_calls=[{'name': 'search_web', 'args': {'query': 'langchain-mcp-adapters library'}, 'id': 'call_YdUV6zTnUL3i3ckAiOQnI13t', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 271, 'output_tokens': 93, 'total_tokens': 364, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}),\n",
      "              ToolMessage(content=[{'type': 'text', 'text': '{\\n  \"query\": \"langchain-mcp-adapters library\",\\n  \"follow_up_questions\": null,\\n  \"answer\": null,\\n  \"images\": [],\\n  \"results\": [\\n    {\\n      \"url\": \"https://medium.com/@deepakkamboj/the-complete-guide-to-langchain-mcp-adapters-bridging-langchain-and-model-context-protocol-3f5507cbd3ca\",\\n      \"title\": \"The Complete Guide to langchain-mcp-adapters - Medium\",\\n      \"content\": \"The langchain-mcp-adapters library serves three primary functions: Tool Conversion: Automatically converts MCP tools into LangChain and\",\\n      \"score\": 0.8765607,\\n      \"raw_content\": null\\n    },\\n    {\\n      \"url\": \"https://pypi.org/project/langchain-mcp-tools/\",\\n      \"title\": \"langchain-mcp-tools - PyPI\",\\n      \"content\": \"LangChain\\'s official LangChain MCP Adapters library, which supports comprehensive integration with LangChain, has been released. You may want to consider using\",\\n      \"score\": 0.8708723,\\n      \"raw_content\": null\\n    },\\n    {\\n      \"url\": \"https://changelog.langchain.com/announcements/mcp-adapters-for-langchain-and-langgraph\",\\n      \"title\": \"MCP Adapters for LangChain and LangGraph\",\\n      \"content\": \"# LangChain Changelog. Sign up for our newsletter to stay up to date. # MCP Adapters for LangChain and LangGraph. The **LangChain MCP Adapters** is a package that makes it easy to use **Anthropic Model Context Protocol (MCP) tools** with LangChain & LangGraph. * Converts **MCP tools** into **LangChain- & LangGraph-compatible tools**. * Enables interaction with tools across multiple **MCP servers**. * Seamlessly integrates the **hundreds of tool servers** already published into LangGraph Agents. ### Why use MCP Adapters:. This adapter makes it simple to connect LangChain and LangGraph with the growing ecosystem of MCP tool servers. Instead of manually adapting each tool, you can now integrate them seamlessly. It also allows agents to pull from multiple MCP servers at once, making it easier to combine different tools for more powerful applications. MCP is gaining serious traction, and this adapter helps LangGraph agents take full advantage. ##### Subscribe to updates.\",\\n      \"score\": 0.86981434,\\n      \"raw_content\": null\\n    },\\n    {\\n      \"url\": \"https://www.npmjs.com/package/@langchain/mcp-adapters\",\\n      \"title\": \"langchain/mcp-adapters - NPM\",\\n      \"content\": \"The library allows you to connect to one or more MCP servers and load tools from them, without needing to manage your own MCP client instances. // Whether to throw on errors if a tool fails to load (optional, default: true). // Whether to prefix tool names with the server name (optional, default: false). // Whether to throw errors if a tool fails to load (optional, default: true). When calling tools from the `camera` MCP server, the following `outputHandling` config will be used:. Similarly, when calling tools on the `microphone` MCP server, the following `outputHandling` config will be used:. You can include a `defaultToolTimeout` field in the server config to set the timeout for all tools for that server, or globally for the entire client by setting it in the top-level config. For secure MCP servers that require OAuth 2.0 authentication, you can use the `authProvider` option instead of manually managing headers. const tools = await client.getTools(); // Only tools from \\\\\"working-server\\\\\".\",\\n      \"score\": 0.85567063,\\n      \"raw_content\": null\\n    },\\n    {\\n      \"url\": \"https://docs.langchain.com/oss/javascript/langchain/mcp\",\\n      \"title\": \"Model Context Protocol (MCP) - Docs by LangChain\",\\n      \"content\": \"Model Context Protocol (MCP) is an open protocol that standardizes how applications provide tools and context to LLMs. LangChain agents can use tools defined on MCP servers using the `@langchain/mcp-adapters` library. import { MultiServerMCPClient } from \\\\\"@langchain/mcp-adapters\\\\\"; import { MultiServerMCPClient } from \\\\\"@langchain/mcp-adapters\\\\\"; import { ChatAnthropic } from \\\\\"@langchain/anthropic\\\\\"; import { ChatAnthropic } from \\\\\"@langchain/anthropic\\\\\";import { createAgent } from \\\\\"langchain\\\\\"; import { createAgent } from  \\\\\"langchain\\\\\"; const client = new MultiServerMCPClient({ const  client =  new  MultiServerMCPClient({  math: { math: { transport: \\\\\"stdio\\\\\", // Local subprocess communication transport:  \\\\\"stdio\\\\\", // Local subprocess communication command: \\\\\"node\\\\\", command:  \\\\\"node\\\\\", // Replace with absolute path to your math_server.js file // Replace with absolute path to your math_server.js file args: [\\\\\"/path/to/math_server.js\\\\\"], args: [\\\\\"/path/to/math_server.js\\\\\"], }, }, weather: { weather: { transport: \\\\\"http\\\\\", // HTTP-based remote server transport:  \\\\\"http\\\\\", // HTTP-based remote server // Ensure you start your weather server on port 8000 // Ensure you start your weather server on port 8000 url: \\\\\"http://localhost:8000/mcp\\\\\", url: \\\\\"http://localhost:8000/mcp\\\\\", }, },});}); const tools = await client.getTools(); const  tools =  await  client.\",\\n      \"score\": 0.8479807,\\n      \"raw_content\": null\\n    }\\n  ],\\n  \"response_time\": 0.94,\\n  \"request_id\": \"aeeb4be4-943c-4a74-b524-b7f55efc7097\"\\n}', 'id': 'lc_1825a541-8f42-4c31-ad2b-5461efc1cb5a'}], name='search_web', id='4e284d23-4fe4-4501-8e90-113702928156', tool_call_id='call_YdUV6zTnUL3i3ckAiOQnI13t', artifact={'structured_content': {'result': {'query': 'langchain-mcp-adapters library', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://medium.com/@deepakkamboj/the-complete-guide-to-langchain-mcp-adapters-bridging-langchain-and-model-context-protocol-3f5507cbd3ca', 'title': 'The Complete Guide to langchain-mcp-adapters - Medium', 'content': 'The langchain-mcp-adapters library serves three primary functions: Tool Conversion: Automatically converts MCP tools into LangChain and', 'score': 0.8765607, 'raw_content': None}, {'url': 'https://pypi.org/project/langchain-mcp-tools/', 'title': 'langchain-mcp-tools - PyPI', 'content': \"LangChain's official LangChain MCP Adapters library, which supports comprehensive integration with LangChain, has been released. You may want to consider using\", 'score': 0.8708723, 'raw_content': None}, {'url': 'https://changelog.langchain.com/announcements/mcp-adapters-for-langchain-and-langgraph', 'title': 'MCP Adapters for LangChain and LangGraph', 'content': '# LangChain Changelog. Sign up for our newsletter to stay up to date. # MCP Adapters for LangChain and LangGraph. The **LangChain MCP Adapters** is a package that makes it easy to use **Anthropic Model Context Protocol (MCP) tools** with LangChain & LangGraph. * Converts **MCP tools** into **LangChain- & LangGraph-compatible tools**. * Enables interaction with tools across multiple **MCP servers**. * Seamlessly integrates the **hundreds of tool servers** already published into LangGraph Agents. ### Why use MCP Adapters:. This adapter makes it simple to connect LangChain and LangGraph with the growing ecosystem of MCP tool servers. Instead of manually adapting each tool, you can now integrate them seamlessly. It also allows agents to pull from multiple MCP servers at once, making it easier to combine different tools for more powerful applications. MCP is gaining serious traction, and this adapter helps LangGraph agents take full advantage. ##### Subscribe to updates.', 'score': 0.86981434, 'raw_content': None}, {'url': 'https://www.npmjs.com/package/@langchain/mcp-adapters', 'title': 'langchain/mcp-adapters - NPM', 'content': 'The library allows you to connect to one or more MCP servers and load tools from them, without needing to manage your own MCP client instances. // Whether to throw on errors if a tool fails to load (optional, default: true). // Whether to prefix tool names with the server name (optional, default: false). // Whether to throw errors if a tool fails to load (optional, default: true). When calling tools from the `camera` MCP server, the following `outputHandling` config will be used:. Similarly, when calling tools on the `microphone` MCP server, the following `outputHandling` config will be used:. You can include a `defaultToolTimeout` field in the server config to set the timeout for all tools for that server, or globally for the entire client by setting it in the top-level config. For secure MCP servers that require OAuth 2.0 authentication, you can use the `authProvider` option instead of manually managing headers. const tools = await client.getTools(); // Only tools from \"working-server\".', 'score': 0.85567063, 'raw_content': None}, {'url': 'https://docs.langchain.com/oss/javascript/langchain/mcp', 'title': 'Model Context Protocol (MCP) - Docs by LangChain', 'content': 'Model Context Protocol (MCP) is an open protocol that standardizes how applications provide tools and context to LLMs. LangChain agents can use tools defined on MCP servers using the `@langchain/mcp-adapters` library. import { MultiServerMCPClient } from \"@langchain/mcp-adapters\"; import { MultiServerMCPClient } from \"@langchain/mcp-adapters\"; import { ChatAnthropic } from \"@langchain/anthropic\"; import { ChatAnthropic } from \"@langchain/anthropic\";import { createAgent } from \"langchain\"; import { createAgent } from  \"langchain\"; const client = new MultiServerMCPClient({ const  client =  new  MultiServerMCPClient({  math: { math: { transport: \"stdio\", // Local subprocess communication transport:  \"stdio\", // Local subprocess communication command: \"node\", command:  \"node\", // Replace with absolute path to your math_server.js file // Replace with absolute path to your math_server.js file args: [\"/path/to/math_server.js\"], args: [\"/path/to/math_server.js\"], }, }, weather: { weather: { transport: \"http\", // HTTP-based remote server transport:  \"http\", // HTTP-based remote server // Ensure you start your weather server on port 8000 // Ensure you start your weather server on port 8000 url: \"http://localhost:8000/mcp\", url: \"http://localhost:8000/mcp\", }, },});}); const tools = await client.getTools(); const  tools =  await  client.', 'score': 0.8479807, 'raw_content': None}], 'response_time': 0.94, 'request_id': 'aeeb4be4-943c-4a74-b524-b7f55efc7097'}}}),\n",
      "              AIMessage(content='Here’s a concise overview of the langchain-mcp-adapters library and how it fits into LangChain/LangGraph.\\n\\nWhat it is\\n- A library that bridges the Anthropic Model Context Protocol (MCP) with LangChain and LangGraph.\\n- It automatically converts MCP tools into LangChain- and LangGraph-compatible tools.\\n- It lets you interact with tools from multiple MCP servers and use them inside LangChain/LangGraph agents.\\n\\nKey features\\n- Tool conversion: MCP tools are automatically exposed as LangChain tools so you can use them in agents and tool-using prompts.\\n- Multi-server access: Load and query tools from multiple MCP servers in a single client.\\n- Easy integration: Works with existing MCP tool servers without writing custom adapters for each tool.\\n- Cross-server tool composition: Agents can pull from several MCP servers at once to compose richer toolsets.\\n- Server-specific configuration: You can configure per-server behavior (e.g., outputHandling, timeouts, auth).\\n- Security options: Supports authProvider for OAuth 2.0 or other auth schemes.\\n- LangChain + LangGraph compatibility: Designed to work seamlessly with both LangChain and LangGraph tooling.\\n\\nWhere to get it\\n- JavaScript/TypeScript: @langchain/mcp-adapters (NPM)\\n  - Typical usage: create a MultiServerMCPClient with a config that describes each MCP server (transport, url or local process, etc.), call getTools(), then convert or use those tools inside LangChain/LangGraph workflows.\\n- Python: There is a Python ecosystem around MCP adapters as well, with the PyPI package langchain-mcp-tools. This provides a Python-facing way to connect to MCP servers and use MCP tools in LangChain workflows there.\\n\\nQuickstart ideas (JavaScript/TypeScript)\\n- Install: npm i @langchain/mcp-adapters\\n- Create a client that talks to multiple MCP servers (examples often show stdio-based local servers and HTTP-based remote servers):\\n  - Example servers config might include a math server (stdio transport) and a weather server (http transport with a URL).\\n- Get tools from the MCP servers: tools = await client.getTools();\\n- Use those tools inside LangChain/LangGraph by converting them to LangChain tools or by wiring them into an agent.\\n\\nWhere to read more\\n- LangChain MCP documentation: Model Context Protocol (MCP) docs show how to use MultiServerMCPClient, load tools, and integrate with agents.\\n- LangChain changelog: MCP Adapters for LangChain and LangGraph (official notes on capabilities and usage).\\n- Community guide: The complete guide on “langchain-mcp-adapters” (Medium) explaining tool conversion, multi-server support, and usage patterns.\\n- NPM page for JS library with config options, usage notes, and examples.\\n- PyPI page for langchain-mcp-tools if you’re working in Python (Python-side MCP adapters).\\n\\nWould you like a concrete example in JS or Python? I can provide a small, runnable snippet showing:\\n- how to instantiate a MultiServerMCPClient with two servers,\\n- how to fetch tools,\\n- and a minimal way to use those tools in a LangChain agent.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2774, 'prompt_tokens': 1547, 'total_tokens': 4321, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 2112, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D7Uvhgpc5HlFf7sdX5V1YPMycIgPt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c44b9-ed28-7bd0-b4cc-76fe119a2078-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1547, 'output_tokens': 2774, 'total_tokens': 4321, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 2112}})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847409a3",
   "metadata": {},
   "source": [
    "## Online MCP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b2895fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"time\": {\n",
    "            \"transport\": \"stdio\",\n",
    "            \"command\": \"uvx\",\n",
    "            \"args\": [\n",
    "                \"mcp-server-time\",\n",
    "                \"--local-timezone=America/New_York\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "tools = await client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e264dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4725cee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What time is it?', additional_kwargs={}, response_metadata={}, id='0875bcec-ac0a-430b-a8d2-36ccbcc56507'),\n",
      "              AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 219, 'prompt_tokens': 296, 'total_tokens': 515, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D7Uwc1ZspGnudK2nPiibQmQN9KFxv', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c44ba-cbda-78f1-a1f2-cf4e0bd66354-0', tool_calls=[{'name': 'get_current_time', 'args': {'timezone': 'America/New_York'}, 'id': 'call_XhgUVLeKPs0cT2nocQNwyYx5', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 296, 'output_tokens': 219, 'total_tokens': 515, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}),\n",
      "              ToolMessage(content=[{'type': 'text', 'text': '{\\n  \"timezone\": \"America/New_York\",\\n  \"datetime\": \"2026-02-09T18:27:01-05:00\",\\n  \"day_of_week\": \"Monday\",\\n  \"is_dst\": false\\n}', 'id': 'lc_fcfc48e4-e1b0-4d76-913b-8addee410209'}], name='get_current_time', id='7f04df9a-d48c-44b4-86df-a9764ac8768f', tool_call_id='call_XhgUVLeKPs0cT2nocQNwyYx5'),\n",
      "              AIMessage(content='Current time in America/New_York (Eastern Standard Time): Monday, February 9, 2026, 6:27 PM (18:27 UTC-5).\\n\\nWould you like this in another time zone or need a conversion?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 505, 'prompt_tokens': 379, 'total_tokens': 884, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-D7UwgmfzIsUqwf8OW7mI6msH4m4cv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c44ba-da21-78b2-9c5d-521266a8cdbf-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 379, 'output_tokens': 505, 'total_tokens': 884, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 448}})]}\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessage(content=\"What time is it?\")\n",
    "\n",
    "response = await agent.ainvoke(\n",
    "    {\"messages\": [question]}\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc5152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
